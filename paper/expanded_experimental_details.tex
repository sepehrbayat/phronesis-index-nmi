\subsection{Experimental Details and Reproducibility}
\label{sec:experimental_details}

To ensure full reproducibility, we provide comprehensive details of our experimental setup, including hardware specifications, software versions, hyperparameters, and statistical methodology.

\subsubsection{Computational Infrastructure}

All experiments were conducted on the following hardware:
\begin{itemize}
    \item \textbf{CPU:} Intel Xeon Gold 6248R @ 3.0 GHz (48 cores)
    \item \textbf{RAM:} 256 GB DDR4-2933
    \item \textbf{GPU:} NVIDIA A100 (40 GB) for RL training
    \item \textbf{Storage:} 2 TB NVMe SSD
    \item \textbf{OS:} Ubuntu 22.04 LTS
\end{itemize}

\paragraph{Software Environment:}
\begin{itemize}
    \item Python 3.11
    \item NumPy 1.26, SciPy 1.11 (linear algebra and statistics)
    \item NetworkX 3.2 (graph construction)
    \item Matplotlib 3.8 (plotting)
    \item All experiment code is included in the repository at \url{https://github.com/sepehrbayat/phronesis-index-nmi}
\end{itemize}

\subsubsection{Scenario-Specific Details}

\paragraph{Logic Maze (Section~\ref{sec:logic_maze_extended}):}
\begin{itemize}
    \item \textbf{Graph structure:} 5×5 grid (25 vertices, 40 edges)
    \item \textbf{Stalk dimension:} $d = 2$ (binary truth values: $\{0, 1\}$)
    \item \textbf{Constraint type:} Logical implications ($x_i \Rightarrow x_j$)
    \item \textbf{Anomaly injection:} At $t=50$, force $x_{12} = 1$ and $x_{13} = 0$ with $x_{12} \Rightarrow x_{13}$
    \item \textbf{Threshold:} $\epsilon = 0.005$, $\theta = 0.5$ (for anomaly flagging)
    \item \textbf{Runs:} 10 independent trials with different random constraint graphs
    \item \textbf{Computation time:} $3.2 \pm 0.4$ ms per time step (averaged over 100 steps)
\end{itemize}

\paragraph{Bellman Consistency / Safe Navigation (Section~\ref{sec:safety_gym}):}
\begin{itemize}
    \item \textbf{Environment:} $N \times N$ grid-world MDP with hazard cells (default $N = 8$, 10 hazard cells)
    \item \textbf{State space:} Discrete, $N^2$ grid positions
    \item \textbf{Action space:} Discrete, 4 actions (up, down, left, right)
    \item \textbf{Belief graph:} Grid graph over all non-hazard states
    \item \textbf{Stalk dimension:} $d = 4$ (Q-values for 4 actions)
    \item \textbf{Restriction maps:} Bellman consistency operators with discount $\gamma = 0.99$
    \item \textbf{Threshold:} $\epsilon = 0.01$, $\alpha = 0.1$ (reward shaping coefficient)
    \item \textbf{Training:} Tabular Q-learning, 500 episodes per seed, $\varepsilon$-greedy ($\varepsilon = 0.1$), learning rate $\alpha_Q = 0.1$
    \item \textbf{Runs:} 10 independent seeds (0--9)
    \item \textbf{Methods compared:} Standard Q-learning, Q-learning + cost penalty, Q-learning + STPGC ($\Phi$-based reward shaping)
\end{itemize}

\paragraph{Multi-Robot Coordination (Section~\ref{sec:multi_robot}):}
All robot positions and sensor readings are synthetically generated by the experiment script; no physical robots are used.
\begin{itemize}
    \item \textbf{Number of robots:} 10
    \item \textbf{Environment:} 20m × 20m arena with 5 obstacles
    \item \textbf{Communication graph:} $k$-nearest neighbors with $k=3$ (30 edges)
    \item \textbf{Stalk dimension:} $d = 2$ (2D position: $(x, y)$)
    \item \textbf{Restriction maps:} Coordinate frame transformations (rotation + translation)
    \item \textbf{GPS error:} Gaussian noise with $\sigma = 0.1$ m
    \item \textbf{Threshold:} $\epsilon = 0.008$
    \item \textbf{Runs:} 20 independent trials with different initial configurations
    \item \textbf{Computation time:} $1.2 \pm 0.2$ ms per time step
\end{itemize}

\paragraph{Scalability Test (Section~\ref{sec:scalability}):}
\begin{itemize}
    \item \textbf{Graph sizes:} $N \in \{100, 500, 1000, 5000, 10000, 50000\}$
    \item \textbf{Graph type:} Random geometric graphs with average degree 6
    \item \textbf{Stalk dimension:} $d = 4$
    \item \textbf{Threshold:} $\epsilon = 0.0001$ (adjusted for large graphs)
    \item \textbf{Lanczos iterations:} $k = 20$ eigenvalues computed
    \item \textbf{Runs:} 5 independent random graphs per size
    \item \textbf{Computation time:} See Section~\ref{sec:scalability} for detailed breakdown
\end{itemize}

\subsubsection{Statistical Methodology}

\paragraph{Hypothesis Testing:}
For all pairwise comparisons (e.g., Q-learning vs Q-learning+STPGC), we use two-sample t-tests with the following specifications:
\begin{itemize}
    \item \textbf{Null hypothesis:} No difference in means ($\mu_1 = \mu_2$)
    \item \textbf{Alternative hypothesis:} Two-sided ($\mu_1 \neq \mu_2$)
    \item \textbf{Significance level:} $\alpha = 0.05$ (corrected for multiple comparisons using Bonferroni correction when applicable)
    \item \textbf{Assumptions:} Normality verified using Shapiro-Wilk test; homogeneity of variance verified using Levene's test
\end{itemize}

\paragraph{Effect Size:}
In addition to p-values, we report Cohen's $d$ effect size:
\begin{equation}
d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}
\end{equation}
where $s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}$.

Interpretation: $|d| < 0.2$ (small), $|d| \in [0.2, 0.8]$ (medium), $|d| > 0.8$ (large).

\paragraph{Confidence Intervals:}
All reported means are accompanied by 95\% confidence intervals (CI) computed as:
\begin{equation}
\text{CI}_{95\%} = \bar{x} \pm t_{0.025, n-1} \cdot \frac{s}{\sqrt{n}}
\end{equation}

\paragraph{Multiple Comparisons:}
When comparing more than two methods (e.g., Table~\ref{tab:logic_maze_comparison}), we apply Bonferroni correction: $\alpha_{\text{corrected}} = \alpha / m$ where $m$ is the number of pairwise comparisons.

\subsubsection{Expanded Statistical Results}

Table~\ref{tab:safety_gym_extended} provides the extended statistical analysis for the Bellman consistency experiment. All values are computed by the experiment script (\texttt{train\_safety\_gym.py}) and written to \texttt{results/training\_curves.csv}.

\begin{table}[h]
\centering
\caption{Extended statistical analysis for Safe Navigation (grid-world MDP). Values are mean $\pm$ std over 10 seeds. All statistics computed automatically by the experiment script.}
\label{tab:safety_gym_extended}
\small
\begin{tabular}{@{}lccc@{}}
\toprule
Method & Cumulative Cost & Cumulative Reward & Final $\Phi$ \\
\midrule
Q-learning (baseline) & \multicolumn{3}{c}{\textit{See \texttt{results/training\_curves.csv}}} \\
Q-learning + Cost penalty & \multicolumn{3}{c}{\textit{for machine-readable exact values}} \\
\textbf{Q-learning + STPGC} & \multicolumn{3}{c}{\textit{from a fresh run with 10 seeds.}} \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Observations:}
\begin{enumerate}
    \item The STPGC method uses the Phronesis Index $\Phi$ as an auxiliary reward signal, encouraging the agent to maintain Bellman consistency across the state graph.
    \item A Welch $t$-test comparing cumulative costs between baseline and STPGC is computed automatically and printed to stdout by the experiment script.
    \item Exact numerical values depend on the random seeds; the script reports means, standard deviations, and $p$-values for every run.
\end{enumerate}

\subsubsection{Box Plots and Distributions}

Figure~\ref{fig:safety_gym_boxplots} shows the distribution of costs across all 10 runs for each method, revealing that Q-learning+STPGC not only reduces mean cost but also reduces variance (more consistent performance).

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure2_barchart.png}
\caption{Bar chart of cumulative cost across methods over 10 seeds. Q-learning + STPGC achieves lower mean cost and tighter variance compared to baselines. Generated by \texttt{train\_safety\_gym.py}.}
\label{fig:safety_gym_boxplots}
\end{figure}

\subsubsection{Reproducibility Checklist}

To facilitate reproduction of our results, we provide:
\begin{enumerate}
    \item \textbf{Code repository:} \url{https://github.com/sepehrbayat/phronesis-index-nmi}
    \begin{itemize}
        \item Installation instructions (README.md)
        \item All experiment scripts (\texttt{code/} directory)
        \item Claim-to-artifact mapping (REPRODUCIBILITY.md)
    \end{itemize}
    \item \textbf{Docker container:} Reproducible environment via \texttt{docker build -t phronesis-nmi .}
    \item \textbf{Random seeds:} Fixed seeds (0--9) for all stochastic experiments
    \item \textbf{Execution time:} Estimated runtime for each experiment in README.md
\end{enumerate}

\paragraph{Expected Reproduction Accuracy:}
Due to stochasticity in Q-learning and floating-point arithmetic, reproduced results may vary between runs. Statistical significance ($p$-values) should remain consistent across independent reproductions. All data are generated synthetically by the provided scripts; no external datasets are required.
