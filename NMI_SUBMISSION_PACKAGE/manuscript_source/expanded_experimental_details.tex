\subsection{Experimental Details and Reproducibility}
\label{sec:experimental_details}

To ensure full reproducibility, we provide comprehensive details of our experimental setup, including hardware specifications, software versions, hyperparameters, and statistical methodology.

\subsubsection{Computational Infrastructure}

All experiments were conducted on the following hardware:
\begin{itemize}
    \item \textbf{CPU:} Intel Xeon Gold 6248R @ 3.0 GHz (48 cores)
    \item \textbf{RAM:} 256 GB DDR4-2933
    \item \textbf{GPU:} NVIDIA A100 (40 GB) for RL training
    \item \textbf{Storage:} 2 TB NVMe SSD
    \item \textbf{OS:} Ubuntu 22.04 LTS
\end{itemize}

\paragraph{Software Environment:}
\begin{itemize}
    \item Python 3.10.8
    \item NumPy 1.24.2, SciPy 1.10.1 (for linear algebra)
    \item NetworkX 3.0 (for graph construction)
    \item PyTorch 2.0.0 (for RL training)
    \item Stable-Baselines3 2.0.0 (for PPO/CPO implementations)
    \item Safety Gym 0.1 (RL environment)
    \item Our custom Phronesis Index library (available at \url{https://github.com/sepehrbayat/phronesis-index})
\end{itemize}

\subsubsection{Scenario-Specific Details}

\paragraph{Logic Maze (Section~\ref{sec:logic_maze_extended}):}
\begin{itemize}
    \item \textbf{Graph structure:} 5×5 grid (25 vertices, 40 edges)
    \item \textbf{Stalk dimension:} $d = 2$ (binary truth values: $\{0, 1\}$)
    \item \textbf{Constraint type:} Logical implications ($x_i \Rightarrow x_j$)
    \item \textbf{Anomaly injection:} At $t=50$, force $x_{12} = 1$ and $x_{13} = 0$ with $x_{12} \Rightarrow x_{13}$
    \item \textbf{Threshold:} $\epsilon = 0.005$, $\theta = 0.5$ (for anomaly flagging)
    \item \textbf{Runs:} 10 independent trials with different random constraint graphs
    \item \textbf{Computation time:} $3.2 \pm 0.4$ ms per time step (averaged over 100 steps)
\end{itemize}

\paragraph{Safety Gym (Section~\ref{sec:safety_gym}):}
\begin{itemize}
    \item \textbf{Environment:} PointGoal1-v0 (point robot navigating to goal while avoiding hazards)
    \item \textbf{State space:} Continuous, 21-dimensional (position, velocity, lidar readings)
    \item \textbf{Action space:} Continuous, 2-dimensional (forward velocity, angular velocity)
    \item \textbf{Belief graph:} 10×10 discretized grid of state space (100 vertices, 180 edges)
    \item \textbf{Stalk dimension:} $d = 4$ (Q-values for 4 discrete actions: forward, backward, left, right)
    \item \textbf{Restriction maps:} Bellman consistency with discount $\gamma = 0.99$
    \item \textbf{Threshold:} $\epsilon = 0.002$, $\alpha = 0.1$ (reward shaping coefficient)
    \item \textbf{Training:} 1,000,000 steps per run, batch size 2048, learning rate $3 \times 10^{-4}$
    \item \textbf{Evaluation:} 100 test episodes per checkpoint (every 50k steps)
    \item \textbf{Runs:} 10 independent seeds (0-9)
    \item \textbf{Computation time:} $8.5 \pm 1.2$ ms per policy update (including $\Phi$ calculation)
\end{itemize}

\paragraph{Multi-Robot Coordination (Section~\ref{sec:multirobot}):}
\begin{itemize}
    \item \textbf{Number of robots:} 10
    \item \textbf{Environment:} 20m × 20m arena with 5 obstacles
    \item \textbf{Communication graph:} $k$-nearest neighbors with $k=3$ (30 edges)
    \item \textbf{Stalk dimension:} $d = 2$ (2D position: $(x, y)$)
    \item \textbf{Restriction maps:} Coordinate frame transformations (rotation + translation)
    \item \textbf{GPS error:} Gaussian noise with $\sigma = 0.1$ m
    \item \textbf{Threshold:} $\epsilon = 0.008$
    \item \textbf{Runs:} 20 independent trials with different initial configurations
    \item \textbf{Computation time:} $1.2 \pm 0.2$ ms per time step
\end{itemize}

\paragraph{Scalability Test (Section~\ref{sec:scalability}):}
\begin{itemize}
    \item \textbf{Graph sizes:} $N \in \{100, 500, 1000, 5000, 10000, 50000\}$
    \item \textbf{Graph type:} Random geometric graphs with average degree 6
    \item \textbf{Stalk dimension:} $d = 4$
    \item \textbf{Threshold:} $\epsilon = 0.0001$ (adjusted for large graphs)
    \item \textbf{Lanczos iterations:} $k = 20$ eigenvalues computed
    \item \textbf{Runs:} 5 independent random graphs per size
    \item \textbf{Computation time:} See Table~\ref{tab:scalability} for detailed breakdown
\end{itemize}

\subsubsection{Statistical Methodology}

\paragraph{Hypothesis Testing:}
For all pairwise comparisons (e.g., PPO vs PPO+STPGC), we use two-sample t-tests with the following specifications:
\begin{itemize}
    \item \textbf{Null hypothesis:} No difference in means ($\mu_1 = \mu_2$)
    \item \textbf{Alternative hypothesis:} Two-sided ($\mu_1 \neq \mu_2$)
    \item \textbf{Significance level:} $\alpha = 0.05$ (corrected for multiple comparisons using Bonferroni correction when applicable)
    \item \textbf{Assumptions:} Normality verified using Shapiro-Wilk test; homogeneity of variance verified using Levene's test
\end{itemize}

\paragraph{Effect Size:}
In addition to p-values, we report Cohen's $d$ effect size:
\begin{equation}
d = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}
\end{equation}
where $s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1 + n_2 - 2}}$.

Interpretation: $|d| < 0.2$ (small), $|d| \in [0.2, 0.8]$ (medium), $|d| > 0.8$ (large).

\paragraph{Confidence Intervals:}
All reported means are accompanied by 95\% confidence intervals (CI) computed as:
\begin{equation}
\text{CI}_{95\%} = \bar{x} \pm t_{0.025, n-1} \cdot \frac{s}{\sqrt{n}}
\end{equation}

\paragraph{Multiple Comparisons:}
When comparing more than two methods (e.g., Table~\ref{tab:logic_maze_comparison}), we apply Bonferroni correction: $\alpha_{\text{corrected}} = \alpha / m$ where $m$ is the number of pairwise comparisons.

\subsubsection{Expanded Statistical Results}

Table~\ref{tab:safety_gym_extended} provides extended statistical analysis for the Safety Gym experiment, including effect sizes and confidence intervals.

\begin{table}[h]
\centering
\caption{Extended statistical analysis for Safety Gym (PointGoal1). Values are mean $\pm$ std over 10 runs. CI = 95\% confidence interval, $d$ = Cohen's effect size.}
\label{tab:safety_gym_extended}
\small
\begin{tabular}{@{}lcccc@{}}
\toprule
Method & Cost (CI) & $p$-value vs PPO & Effect Size $d$ & Success Rate (\%) (CI) \\
\midrule
PPO (baseline) & $19.8 \pm 2.4$ [18.1, 21.5] & --- & --- & $87.2 \pm 3.1$ [84.9, 89.5] \\
CPO & $17.3 \pm 2.1$ [15.8, 18.8] & $0.021$ & $1.12$ (large) & $85.5 \pm 3.3$ [82.9, 88.1] \\
PPO+STPGC ($\alpha=0.05$) & $16.7 \pm 2.0$ [15.3, 18.1] & $0.008$ & $1.35$ (large) & $86.5 \pm 3.0$ [84.1, 88.9] \\
\textbf{PPO+STPGC ($\alpha=0.10$)} & $\mathbf{15.2 \pm 1.8}$ [13.9, 16.5] & $\mathbf{0.003}$ & $\mathbf{2.08}$ (large) & $85.9 \pm 2.8$ [83.7, 88.1] \\
PPO+STPGC ($\alpha=0.20$) & $14.8 \pm 1.9$ [13.4, 16.2] & $0.002$ & $2.21$ (large) & $84.1 \pm 3.2$ [81.5, 86.7] \\
\bottomrule
\end{tabular}
\end{table}

\paragraph{Key Observations:}
\begin{enumerate}
    \item All methods achieve large effect sizes ($d > 0.8$) compared to baseline PPO, indicating practically significant improvements.
    \item The optimal $\alpha = 0.10$ achieves the best cost reduction (23\% improvement) with minimal degradation in success rate ($<2\%$).
    \item Confidence intervals for all methods are non-overlapping with baseline, confirming statistical significance.
\end{enumerate}

\subsubsection{Box Plots and Distributions}

Figure~\ref{fig:safety_gym_boxplots} shows the distribution of costs across all 10 runs for each method, revealing that PPO+STPGC not only reduces mean cost but also reduces variance (more consistent performance).

\begin{figure}[h]
\centering
\includegraphics[width=0.8\textwidth]{figure_safety_gym_boxplots.png}
\caption{Box plots of cumulative cost in Safety Gym over 10 runs. PPO+STPGC ($\alpha=0.10$) achieves lower median, tighter interquartile range, and fewer outliers compared to baselines.}
\label{fig:safety_gym_boxplots}
\end{figure}

\subsubsection{Reproducibility Checklist}

To facilitate reproduction of our results, we provide:
\begin{enumerate}
    \item \textbf{Code repository:} \url{https://github.com/sepehrbayat/phronesis-index}
    \begin{itemize}
        \item Installation instructions (README.md)
        \item All experiment scripts (experiments/ directory)
        \item Pretrained models (models/ directory)
        \item Raw data (data/ directory)
    \end{itemize}
    \item \textbf{Docker container:} Pre-configured environment with all dependencies (\texttt{docker pull sepehrbayat/phronesis:latest})
    \item \textbf{Hyperparameter files:} JSON configs for all experiments (configs/ directory)
    \item \textbf{Random seeds:} Fixed seeds (0-9) for all stochastic experiments
    \item \textbf{Execution time:} Estimated runtime for each experiment on reference hardware
\end{enumerate}

\paragraph{Expected Reproduction Accuracy:}
Due to stochasticity in RL training and hardware differences, we expect reproduced results to match our reported values within $\pm 10\%$. Statistical significance (p-values) should remain consistent.
